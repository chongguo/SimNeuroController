{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "from alexnet_pytorch import AlexNet as alexnet2\n",
    "from util.layervisualization import CNNLayerVisualization\n",
    "from util.modelregressions import CNNCrossFit\n",
    "from util.misc_functions import float2rgb\n",
    "from dataset.hvm import HVMDataset\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated controller\n",
    "\n",
    "Here the objective was to see if Pouya's original finding (EV =/= strech control) holds even for simulated neural control.\n",
    "We modified the metric to be strech control with source model vs. with target model. Using hvm data for mapping, range of sample size (200:500:1000:5000), we find qualitatively very similar phenomena. Unclear if using imagenet we will set any difference as a function a sample size. We defer this to a subsequent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up target and source models\n",
    "squeezenet_target = models.squeezenet1_0(pretrained=True).features\n",
    "squeezenet_source = models.squeezenet1_1(pretrained=True).features\n",
    "alexnet_source = models.alexnet(pretrained=True).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define basic params \n",
    "cnn_layer = 12\n",
    "source_units = np.arange(128)\n",
    "target_units = np.arange(128)\n",
    "img_dim = [256,256,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:19<00:00, 14.14s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:20<00:00, 14.09s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() missing 2 required positional arguments: 'n_train' and 'n_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1aba9625579e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msnet2snet200\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhvmdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecord_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# linear prediction of target unit, record performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msnet2snet200\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# implement source control of target units, record performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msnet2snet200\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 2 required positional arguments: 'n_train' and 'n_test'"
     ]
    }
   ],
   "source": [
    "# pre-load data into memory for speed\n",
    "hvmdataset = HVMDataset(2000)\n",
    "# create a control experiment (squeezenet1_1-->squeezenet1_0)\n",
    "snet2snet200 = CNNCrossFit(squeezenet_target,squeezenet_source,cnn_layer,target_units,source_units)\n",
    "# extract layer activation across two models\n",
    "snet2snet200.design(hvmdataset,1000,1000,record_gradient = False)\n",
    "# linear prediction of target unit, record performance\n",
    "snet2snet200.fit(1000,1000)\n",
    "# implement source control of target units, record performance\n",
    "snet2snet200.control()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(snet2snet200.train_score,snet2snet200.test_score,'.')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim((0,1))\n",
    "plt.xlabel('train score')\n",
    "plt.ylabel('test score')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(snet2snet200.target_act,snet2snet200.source_act,'.')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('optimized act. target model')\n",
    "plt.ylabel('optimized act. source model')\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(snet2snet200.test_score,snet2snet200.ctr_score,'.',label='2000')\n",
    "plt.legend()\n",
    "plt.xlim((0,1))\n",
    "plt.ylim((0,1))\n",
    "plt.xlabel('test score')\n",
    "plt.ylabel('fraction act. source/target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that Pouya's original result seems to hold in this simple scenario by looking at the plot on the right.\n",
    "This control objective is not guarenteed to acheive a large activation because it is discoverying the same image as optimizing on the target network directly. Check the images in the generated folder for clear visual illustrations of this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two feature visualization objects\n",
    "img_dim = [256,256,3]\n",
    "niter = 100\n",
    "layer_vis_target = CNNLayerVisualization(squeezenet_target, cnn_layer, target_units[0],img_dim)\n",
    "\n",
    "# Image sythesis with pytorch hooks\n",
    "[Img_target, target_val] = layer_vis_target.visualise_layer_with_hooks(niter=niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((img_dim[0]*img_dim[1]*img_dim[2],niter))\n",
    "plt.figure(figsize=(15,40))\n",
    "for i in range(niter):\n",
    "    im_path = 'generated/layer_vis_l' + str(cnn_layer) + \\\n",
    "        '_f' + str(source_units[0]) + '_iter' + str(i+1) + '.jpg'\n",
    "    tempimg=mpimg.imread(im_path)\n",
    "    img[:,i] = tempimg.flatten()\n",
    "    if i%(niter/5) == 0:\n",
    "        plt.subplot(1,5,round(i/(niter/5))+1)\n",
    "        plt.imshow(tempimg)\n",
    "        plt.axis('off')\n",
    "        plt.clim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting observation here is that the image evolved appear to be moving in a single principle direction. And the image moves almost linearly along a principle direction in the gradient space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "D = img[:,0:-2:1]-img[:,1:-1:1];\n",
    "[d,n] = D.shape\n",
    "pca = PCA(n_components=n,whiten=False)\n",
    "pca.fit(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dpca = pca.transform(D)\n",
    "Dproj_pc1 = Dpca[:,0].reshape(img_dim)\n",
    "\n",
    "plt.figure(figsize=(15,40))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(float2rgb(tempimg))\n",
    "plt.axis('off')\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(float2rgb(-Dproj_pc1))\n",
    "plt.axis('off')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(float2rgb(D[:,5].reshape(img_dim)))\n",
    "plt.axis('off')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(float2rgb(D[:,-5].reshape(img_dim)))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_,'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This PCA of the gradient vector over all iterations shows a single large eigenvalue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
