{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualtiy of neural control reflects local gradient alignment\n",
    "\n",
    "Here we perform three experiments:\n",
    "1. Gradient alignment vs. standard linear regression EV as a function of sample size\n",
    "2. Original strech/OHP control objective vs. gradient alignment EV from linear mapping\n",
    "3. New vector control objective vs. gradient alignment EV. \n",
    "\n",
    "The goal of #1 is to see whether better pointwise function alignment leads to better gradient alignment.\n",
    "If this is not the case, then this would explan #2. Given these observations we improve upon the control metric's sensitivity to gradient with #3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from util.modelregressions import CNNCrossFit\n",
    "from util.misc_functions import float2rgb\n",
    "from dataset.hvm import HVMDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chong Guo\\AppData\\Local\\conda\\conda\\envs\\torch\\lib\\site-packages\\torchvision\\models\\squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "C:\\Users\\Chong Guo\\AppData\\Local\\conda\\conda\\envs\\torch\\lib\\site-packages\\torchvision\\models\\squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "# load up target and source models\n",
    "squeezenet_target = models.squeezenet1_0(pretrained=True).features.to(device)\n",
    "squeezenet_source = models.squeezenet1_1(pretrained=True).features.to(device)\n",
    "# define basic params \n",
    "cnn_layer = 12\n",
    "source_units = np.arange(512)\n",
    "target_units = np.arange(512)\n",
    "img_dim = [256,256,3]\n",
    "# pre-load data into memory for speed\n",
    "nimg = 10;\n",
    "batch_max = 1;\n",
    "hvmdataset = HVMDataset(device,nimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting activations and input jacobians\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–Š                                                                             | 52/5000 [05:28<8:41:54,  6.33s/it]"
     ]
    }
   ],
   "source": [
    "# create a control experiment (squeezenet1_1-->squeezenet1_0)\n",
    "snet2snet = CNNCrossFit(squeezenet_target,squeezenet_source,cnn_layer,target_units,source_units,device)\n",
    "# extract layer activation across two models\n",
    "snet2snet.design(hvmdataset, batch_size = batch_max, record_gradient = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snet2snet200.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear prediction of target unit, record performance\n",
    "snet2snet.fit(8,2)\n",
    "# score the test set\n",
    "snet2snet.score()\n",
    "# control units\n",
    "snet2snet.control()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(snet2snet.train_score,snet2snet.test_gscore,'.')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim((-5,1))\n",
    "plt.xlabel('train score')\n",
    "plt.ylabel('test gradient score')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(snet2snet.test_gscore,snet2snet.source_act,'.')\n",
    "plt.legend()\n",
    "plt.axis('tight')\n",
    "plt.xlim((-5,1))\n",
    "plt.ylim((lmin-5,lmax/2))\n",
    "plt.xlabel('test gradient score')\n",
    "plt.ylabel('optimized act. source model')\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(snet2snet.test_gscore,snet2snet.ctr_score,'.')\n",
    "plt.legend()\n",
    "plt.xlim((-5,1))\n",
    "plt.ylim((0,1))\n",
    "plt.xlabel('test grad score')\n",
    "plt.ylabel('fraction act. source/target')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
